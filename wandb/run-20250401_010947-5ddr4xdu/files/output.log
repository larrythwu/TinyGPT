step 0: train loss 10.9985, val loss 10.9971
/home/ubuntu/DORC-GPT/train.py:323: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/aten/src/ATen/native/Scalar.cpp:22.)
  lossf = loss.item() * gradient_accumulation_steps
iter 0: loss 10.9894, time 38611.18ms, mfu -100.00%
iter 10: loss 10.1543, time 2549.17ms, mfu 52.82%
iter 20: loss 9.3595, time 2552.41ms, mfu 52.82%
iter 30: loss 9.0046, time 2557.08ms, mfu 52.80%
iter 40: loss 8.7314, time 2561.23ms, mfu 52.78%
iter 50: loss 7.9805, time 2563.37ms, mfu 52.75%
iter 60: loss 7.5753, time 2566.00ms, mfu 52.73%
iter 70: loss 7.3853, time 2567.32ms, mfu 52.70%
iter 80: loss 7.0211, time 2566.44ms, mfu 52.68%
iter 90: loss 6.6078, time 2565.09ms, mfu 52.66%
iter 100: loss 6.3778, time 2566.23ms, mfu 52.64%
iter 110: loss 5.8958, time 2565.22ms, mfu 52.63%
iter 120: loss 5.3958, time 2565.17ms, mfu 52.61%
iter 130: loss 5.2684, time 2565.04ms, mfu 52.60%
iter 140: loss 4.9167, time 2566.43ms, mfu 52.59%
iter 150: loss 4.5804, time 2566.80ms, mfu 52.58%
iter 160: loss 4.2656, time 2566.94ms, mfu 52.56%
iter 170: loss 4.1474, time 2566.51ms, mfu 52.55%
iter 180: loss 3.8546, time 2567.86ms, mfu 52.54%
iter 190: loss 3.8766, time 2565.42ms, mfu 52.54%
iter 200: loss 3.8266, time 2567.48ms, mfu 52.53%
iter 210: loss 3.6854, time 2565.34ms, mfu 52.52%
iter 220: loss 3.7604, time 2565.52ms, mfu 52.52%
iter 230: loss 3.8850, time 2566.97ms, mfu 52.51%
iter 240: loss 3.9229, time 2567.65ms, mfu 52.51%
iter 250: loss 3.6813, time 2566.85ms, mfu 52.50%
iter 260: loss 3.5592, time 2566.58ms, mfu 52.50%
iter 270: loss 4.1073, time 2565.69ms, mfu 52.50%
iter 280: loss 3.4549, time 2565.37ms, mfu 52.50%
iter 290: loss 3.5156, time 2565.19ms, mfu 52.50%
Traceback (most recent call last):
  File "/home/ubuntu/DORC-GPT/train.py", line 305, in <module>
    scaler.scale(loss).backward()
  File "/home/ubuntu/.local/lib/python3.10/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
